如何理解矩阵特征值？



我举一个直观一点的例子吧...我也喜欢数学的直观之美。我们知道，一张图像的像素（如:320 x 320）到了计算机里面事实上就是320x320的矩阵，每一个元素都代表这个像素点的颜色..如果我们把基于特征值的应用，如PCA、向量奇异值分解SVD这种东西放到图像处理上，大概就可以提供一个看得到的、直观的感受。关于SVD的文章可以参考LeftNotEasy的文章：机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用简单的说，SVD的效果就是..用一个规模更小的矩阵去近似原矩阵...这里A就是代表图像的原矩阵..其中的尤其值得关注，它是由A的特征值从大到小放到对角线上的..也就是说，我们可以选择其中的某些具有“代表性”的特征值去近似原矩阵！左边的是原始图片当我把特征值的数量减少几个的时候...后面的图像变“模糊”了..当我把特征值的数量减少几个的时候...后面的图像变“模糊”了..同样地...同样地...关键的地方来了！如果我们只看到这里的模糊..而没有看到计算机（或者说数学）对于人脸的描述，那就太可惜了...我们看到，不论如何模糊，脸部的关键部位（我们人类认为的关键部位）——五官并没有变化太多...这能否说：数学揭示了世界的奥秘？

